{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53c7d78-8a61-4682-a422-8fa4ee06c4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4da761-e9c7-41c8-828a-8ff2b770c8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#main library for object detection\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c27edb-472f-419f-a81d-23f6478d5628",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visual library\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697f0e83-d63b-487b-a38f-4668544bbd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a90b2a3-7601-437f-91be-d989c270a1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class of cnn opensourced by google, used to train classifiers\n",
    "#large coco is a dataset best to train computer vision model\n",
    "config_file = 'ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt'\n",
    "\n",
    "#freezing is used to incorporate graph\n",
    "frozen_model = 'frozen_inference_graph.pb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a268333-6449-4bee-8835-23386197b49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#represnet high level api models\n",
    "model = cv2.dnn_DetectionModel(frozen_model, config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f808b42-1d2a-4d43-84a1-1018866305a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#put label file into class label\n",
    "classLabels = []\n",
    "file_name = 'labels.txt'\n",
    "with open(file_name, 'rt') as fpt:\n",
    "    classLabels = fpt.read().rstrip('\\n').split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98f15ef-562f-4767-a746-a84c85dcac60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55412f21-29be-4811-83fc-79f794313ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "classLabels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a53b74-8109-4c24-a716-6b7f84a64a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#size of new frame\n",
    "model.setInputSize(320,320)\n",
    "\n",
    "#scale factor of value for the frame, parameter will be multiplier of frame value\n",
    "model.setInputScale(1.0/127.5)\n",
    "\n",
    "#mean value of the actual frame itself\n",
    "model.setInputMean((127.5,127.5,127.5))\n",
    "\n",
    "#set the swapRB for every frame\n",
    "model.setInputSwapRB(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dae310-cff3-4d4c-9f49-6d54d0f5357b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('test.jpg')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b1df99-53a2-4371-a764-31e5506d344d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#boundarybox for the object, this will confirm the object detected\n",
    "ClassIndex, confidece, bbox = model.detect(img, confThreshold= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78601b2b-38ca-4e34-993d-7582ca37bf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this will print all the objects in respective of the ibject list\n",
    "print(ClassIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863d6302-de8c-4cb2-afaa-f3c327aa5436",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code determines the font scale, thickness and color of the box and the text on the object\n",
    "font_scale = 3\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "for ClassInd, conf, boxes in zip(ClassIndex.flatten(), confidece.flatten(), bbox):\n",
    "    cv2.rectangle(img, boxes, (255,0,0),2)\n",
    "    cv2.putText(img, classLabels[ClassInd-1], (boxes[0]+10, boxes[1]+40), font, fontScale = font_scale, color =(0,255,0), thickness = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0969f0-5092-4d90-a2c3-8f59ff8368f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#object detection example - picture\n",
    "plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf24c73c-29e8-4507-a2f3-bb392ce07f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#example for video\n",
    "cap = cv2.VideoCapture('pexels-george-morina-5688492 (1080p).mp4')\n",
    "if not cap.isOpened():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    raise IOERROR('Cant open the video')\n",
    "\n",
    "font_scale = 3\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "\n",
    "#reading of the file\n",
    "while True:\n",
    "    ret, frame, = cap.read()\n",
    "\n",
    "    ClassIndex, confidece, bbox = model.detect(frame, confThreshold= 0.55)\n",
    "\n",
    "    print(ClassIndex)\n",
    "\n",
    "    #classifies the boxes and text within the video\n",
    "    if(len(ClassIndex) !=0):\n",
    "        for ClassInd, conf, boxes in zip(ClassIndex.flatten(), confidece.flatten(), bbox):\n",
    "            if(ClassInd<=80):\n",
    "                cv2.rectangle(frame, boxes, (255,0,0),2)\n",
    "                cv2.putText(frame, classLabels[ClassInd-1], (boxes[0]+10, boxes[1]+40), font, fontScale = font_scale, color =(0,255,0), thickness = 3)\n",
    "\n",
    "    cv2.imshow('Object Detection', frame)\n",
    "\n",
    "    \n",
    "    if cv2.waitKey(2) & 0xff == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba82f5d-fd1e-43a1-83b7-39b359523ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#webcam\n",
    "#example for video\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    raise IOERROR('Cant open the video')\n",
    "\n",
    "font_scale = 3\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "\n",
    "#reading of the file\n",
    "while True:\n",
    "    ret, frame, = cap.read()\n",
    "\n",
    "    ClassIndex, confidece, bbox = model.detect(frame, confThreshold= 0.55)\n",
    "\n",
    "    print(ClassIndex)\n",
    "\n",
    "    #classifies the boxes and text within the video\n",
    "    if(len(ClassIndex) !=0):\n",
    "        for ClassInd, conf, boxes in zip(ClassIndex.flatten(), confidece.flatten(), bbox):\n",
    "            if(ClassInd<=80):\n",
    "                cv2.rectangle(frame, boxes, (255,0,0),2)\n",
    "                cv2.putText(frame, classLabels[ClassInd-1], (boxes[0]+10, boxes[1]+40), font, fontScale = font_scale, color =(0,255,0), thickness = 3)\n",
    "\n",
    "    cv2.imshow('Object Detection', frame)\n",
    "\n",
    "    \n",
    "    if cv2.waitKey(2) & 0xff == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c59d90-200a-4a9d-bccb-52349ebae7ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "obj",
   "language": "python",
   "name": "obj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
